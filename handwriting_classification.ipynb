{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWtsPF-xboAC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load all Classification models**"
      ],
      "metadata": {
        "id": "Y8kvN_Nk9Y11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6ozFUvdOTqp",
        "outputId": "5cfee883-e1a9-471a-8bbb-617c9a2f35a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the first layer model which is used to recognise the digit of the input image\n",
        "digit_recognition_model = load_model(os.path.join('drive/MyDrive/AI/models', 'digit_recognition_model.h5'))"
      ],
      "metadata": {
        "id": "c_8sBjmob-U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load handwriting recognition model\n",
        "# the 10 models are stored in a list\n",
        "# the corresponding model will only be called based on the digit recognition model above\n",
        "handwriting_model_list = []\n",
        "\n",
        "for i in range(10):\n",
        "  curr_model = load_model(os.path.join('drive/MyDrive/AI/models', f'handwriting_{i}_recognition_model.h5'))\n",
        "  handwriting_model_list.append(curr_model)"
      ],
      "metadata": {
        "id": "SOWKmrHNcjxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Testing Dataset**"
      ],
      "metadata": {
        "id": "oaDKBHzadzca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_dir = 'drive/MyDrive/AI/test_set_with_labels'\n",
        "member_list = ['CY', 'YJ', 'YO', 'HT', 'ZY']\n",
        "\n",
        "testing_files = []\n",
        "filename_list = []\n",
        "\n",
        "for i in range(10):\n",
        "  temp = []\n",
        "  filename_temp = []\n",
        "  curr_dir = f'{testing_dir}/{i}'\n",
        "  for filename in os.listdir(curr_dir):\n",
        "    # Check if the file has an image extension\n",
        "    if filename.endswith('.png'):\n",
        "        # Create the full file path\n",
        "        file_path = os.path.join(curr_dir, filename)\n",
        "        # Append the file path to the list\n",
        "        temp.append(file_path)\n",
        "        filename_temp.append(filename)\n",
        "\n",
        "  testing_files.append(temp)\n",
        "  filename_list.append(filename_temp)\n",
        "\n",
        "print(testing_files)\n",
        "print(filename_list)\n",
        "print(len(testing_files))\n",
        "\n",
        "loaded_images = []\n",
        "\n",
        "for i in range(len(testing_files)):\n",
        "    temp = []\n",
        "    # fig, axes = plt.subplots(1, 5)\n",
        "\n",
        "    # Display each image in a separate subplot\n",
        "    for j in range(len(testing_files[i])):\n",
        "        print(filename_list[i][j])\n",
        "        img = cv2.imread(testing_files[i][j])\n",
        "        temp.append(img)\n",
        "        # Display the image on the subplot\n",
        "        # axes[j].imshow(img)\n",
        "\n",
        "        # Remove the axis labels for each subplot\n",
        "        # axes[j].axis('off')\n",
        "\n",
        "    loaded_images.append(temp)\n",
        "    # Adjust the spacing between subplots\n",
        "    # plt.tight_layout()\n",
        "\n",
        "    # Show the figure\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "sxBazsdyd4GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68517ddc-0124-49a6-c7ab-fab60d7d6338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['drive/MyDrive/AI/test_set_with_labels/0/YO_0_resized.png', 'drive/MyDrive/AI/test_set_with_labels/0/HT_0_resized.png', 'drive/MyDrive/AI/test_set_with_labels/0/CY_0_resized.png', 'drive/MyDrive/AI/test_set_with_labels/0/ZY_0_resized.png', 'drive/MyDrive/AI/test_set_with_labels/0/YJ_0_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/1/HT_1_resized.png', 'drive/MyDrive/AI/test_set_with_labels/1/YO_1_resized.png', 'drive/MyDrive/AI/test_set_with_labels/1/CY_1_resized.png', 'drive/MyDrive/AI/test_set_with_labels/1/YJ_1_resized.png', 'drive/MyDrive/AI/test_set_with_labels/1/ZY_1_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/2/HT_2_resized.png', 'drive/MyDrive/AI/test_set_with_labels/2/YJ_2_resized.png', 'drive/MyDrive/AI/test_set_with_labels/2/YO_2_resized.png', 'drive/MyDrive/AI/test_set_with_labels/2/ZY_2_resized.png', 'drive/MyDrive/AI/test_set_with_labels/2/CY_2_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/3/YO_3_resized.png', 'drive/MyDrive/AI/test_set_with_labels/3/YJ_3_resized.png', 'drive/MyDrive/AI/test_set_with_labels/3/HT_3_resized.png', 'drive/MyDrive/AI/test_set_with_labels/3/CY_3_resized.png', 'drive/MyDrive/AI/test_set_with_labels/3/ZY_3_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/4/HT_4_resized.png', 'drive/MyDrive/AI/test_set_with_labels/4/YO_4_resized.png', 'drive/MyDrive/AI/test_set_with_labels/4/YJ_4_resized.png', 'drive/MyDrive/AI/test_set_with_labels/4/CY_4_resized.png', 'drive/MyDrive/AI/test_set_with_labels/4/ZY_4_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/5/HT_5_resized.png', 'drive/MyDrive/AI/test_set_with_labels/5/YJ_5_resized.png', 'drive/MyDrive/AI/test_set_with_labels/5/YO_5_resized.png', 'drive/MyDrive/AI/test_set_with_labels/5/ZY_5_resized.png', 'drive/MyDrive/AI/test_set_with_labels/5/CY_5_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/6/HT_6_resized.png', 'drive/MyDrive/AI/test_set_with_labels/6/YO_6_resized.png', 'drive/MyDrive/AI/test_set_with_labels/6/CY_6_resized.png', 'drive/MyDrive/AI/test_set_with_labels/6/YJ_6_resized.png', 'drive/MyDrive/AI/test_set_with_labels/6/ZY_6_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/7/YO_7_resized.png', 'drive/MyDrive/AI/test_set_with_labels/7/YJ_7_resized.png', 'drive/MyDrive/AI/test_set_with_labels/7/HT_7_resized.png', 'drive/MyDrive/AI/test_set_with_labels/7/ZY_7_resized.png', 'drive/MyDrive/AI/test_set_with_labels/7/CY_7_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/8/HT_8_resized.png', 'drive/MyDrive/AI/test_set_with_labels/8/YO_8_resized.png', 'drive/MyDrive/AI/test_set_with_labels/8/YJ_8_resized.png', 'drive/MyDrive/AI/test_set_with_labels/8/CY_8_resized.png', 'drive/MyDrive/AI/test_set_with_labels/8/ZY_8_resized.png'], ['drive/MyDrive/AI/test_set_with_labels/9/HT_9_resized.png', 'drive/MyDrive/AI/test_set_with_labels/9/YO_9_resized.png', 'drive/MyDrive/AI/test_set_with_labels/9/CY_9_resized.png', 'drive/MyDrive/AI/test_set_with_labels/9/ZY_9_resized.png', 'drive/MyDrive/AI/test_set_with_labels/9/YJ_9_resized.png']]\n",
            "[['YO_0_resized.png', 'HT_0_resized.png', 'CY_0_resized.png', 'ZY_0_resized.png', 'YJ_0_resized.png'], ['HT_1_resized.png', 'YO_1_resized.png', 'CY_1_resized.png', 'YJ_1_resized.png', 'ZY_1_resized.png'], ['HT_2_resized.png', 'YJ_2_resized.png', 'YO_2_resized.png', 'ZY_2_resized.png', 'CY_2_resized.png'], ['YO_3_resized.png', 'YJ_3_resized.png', 'HT_3_resized.png', 'CY_3_resized.png', 'ZY_3_resized.png'], ['HT_4_resized.png', 'YO_4_resized.png', 'YJ_4_resized.png', 'CY_4_resized.png', 'ZY_4_resized.png'], ['HT_5_resized.png', 'YJ_5_resized.png', 'YO_5_resized.png', 'ZY_5_resized.png', 'CY_5_resized.png'], ['HT_6_resized.png', 'YO_6_resized.png', 'CY_6_resized.png', 'YJ_6_resized.png', 'ZY_6_resized.png'], ['YO_7_resized.png', 'YJ_7_resized.png', 'HT_7_resized.png', 'ZY_7_resized.png', 'CY_7_resized.png'], ['HT_8_resized.png', 'YO_8_resized.png', 'YJ_8_resized.png', 'CY_8_resized.png', 'ZY_8_resized.png'], ['HT_9_resized.png', 'YO_9_resized.png', 'CY_9_resized.png', 'ZY_9_resized.png', 'YJ_9_resized.png']]\n",
            "10\n",
            "YO_0_resized.png\n",
            "HT_0_resized.png\n",
            "CY_0_resized.png\n",
            "ZY_0_resized.png\n",
            "YJ_0_resized.png\n",
            "HT_1_resized.png\n",
            "YO_1_resized.png\n",
            "CY_1_resized.png\n",
            "YJ_1_resized.png\n",
            "ZY_1_resized.png\n",
            "HT_2_resized.png\n",
            "YJ_2_resized.png\n",
            "YO_2_resized.png\n",
            "ZY_2_resized.png\n",
            "CY_2_resized.png\n",
            "YO_3_resized.png\n",
            "YJ_3_resized.png\n",
            "HT_3_resized.png\n",
            "CY_3_resized.png\n",
            "ZY_3_resized.png\n",
            "HT_4_resized.png\n",
            "YO_4_resized.png\n",
            "YJ_4_resized.png\n",
            "CY_4_resized.png\n",
            "ZY_4_resized.png\n",
            "HT_5_resized.png\n",
            "YJ_5_resized.png\n",
            "YO_5_resized.png\n",
            "ZY_5_resized.png\n",
            "CY_5_resized.png\n",
            "HT_6_resized.png\n",
            "YO_6_resized.png\n",
            "CY_6_resized.png\n",
            "YJ_6_resized.png\n",
            "ZY_6_resized.png\n",
            "YO_7_resized.png\n",
            "YJ_7_resized.png\n",
            "HT_7_resized.png\n",
            "ZY_7_resized.png\n",
            "CY_7_resized.png\n",
            "HT_8_resized.png\n",
            "YO_8_resized.png\n",
            "YJ_8_resized.png\n",
            "CY_8_resized.png\n",
            "ZY_8_resized.png\n",
            "HT_9_resized.png\n",
            "YO_9_resized.png\n",
            "CY_9_resized.png\n",
            "ZY_9_resized.png\n",
            "YJ_9_resized.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict the digit of the input image"
      ],
      "metadata": {
        "id": "S_rhaZnF-QWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the predicted digits are stored in a list\n",
        "pred_res = []\n",
        "\n",
        "for i in range(len(loaded_images)):\n",
        "  print(f'iteration: {i}')\n",
        "  temp = []\n",
        "  for j in range(len(loaded_images[i])):\n",
        "    y_pred = digit_recognition_model.predict(np.expand_dims(loaded_images[i][j]/255, 0))\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=1)\n",
        "    print(y_pred)\n",
        "    print(y_pred_classes)\n",
        "    temp.append(int(y_pred_classes))\n",
        "  pred_res.append(temp)\n",
        "\n",
        "print(pred_res)\n",
        "\n",
        "accuracy_count = 0\n",
        "\n",
        "for i in range(10):\n",
        "  for j in range(5):\n",
        "    if i == pred_res[i][j]:\n",
        "      accuracy_count+=1\n",
        "\n",
        "print(f'Accuracy: {accuracy_count/50*100}%')"
      ],
      "metadata": {
        "id": "g6W2Mcyue0bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c03163-3e1d-4687-e1a8-6cb95b21bd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "[[9.9984372e-01 3.1197359e-16 2.0487664e-07 2.2997231e-11 6.5456374e-09\n",
            "  5.6824882e-14 4.2152650e-09 3.7832980e-13 1.5597443e-04 5.1866766e-12]]\n",
            "tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[9.3777525e-01 1.9116081e-13 5.2203193e-02 1.6748200e-07 1.9771763e-07\n",
            "  3.8849582e-13 2.1740540e-09 1.4356144e-05 1.0000879e-02 5.9456315e-06]]\n",
            "tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "[[9.0621769e-01 1.1455526e-07 7.1559843e-05 1.5279790e-06 7.2780843e-03\n",
            "  5.3087929e-06 1.4516750e-02 6.4087919e-07 1.4542723e-02 5.7365596e-02]]\n",
            "tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "[[1.00000000e+00 2.53374173e-26 9.17224196e-13 1.71456936e-22\n",
            "  1.08229304e-16 3.57889721e-23 1.54432879e-15 1.07090718e-19\n",
            "  7.16397192e-19 1.55889486e-23]]\n",
            "tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[1.0000000e+00 3.3252090e-26 6.9500109e-12 6.2814955e-23 1.9015753e-12\n",
            "  4.0590783e-21 1.3981298e-13 6.4179289e-17 7.9157744e-18 2.5435233e-18]]\n",
            "tf.Tensor([0], shape=(1,), dtype=int64)\n",
            "iteration: 1\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "[[9.0934336e-08 9.9996078e-01 5.4872929e-12 2.7793851e-10 5.4396970e-10\n",
            "  3.5105297e-11 2.4325441e-06 3.6708836e-05 2.0384714e-09 9.2809406e-12]]\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "[[1.8147784e-13 9.9999976e-01 2.3388285e-13 4.6430509e-11 2.1733233e-07\n",
            "  1.2226265e-12 3.5135889e-10 1.0014115e-09 3.1444476e-13 1.3337643e-12]]\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "[[3.6278945e-11 9.9999988e-01 2.1299142e-09 1.4839540e-08 3.4936434e-09\n",
            "  3.4861333e-10 4.1996393e-09 4.4956852e-08 1.5636896e-11 2.7358799e-10]]\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[2.61244731e-18 1.00000000e+00 3.00083368e-19 2.18564160e-16\n",
            "  2.74672819e-11 2.12186385e-18 1.22616600e-14 4.44785186e-13\n",
            "  1.22144906e-17 2.03293904e-18]]\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "[[6.2219479e-15 1.0000000e+00 1.5706903e-15 1.2464343e-12 2.0980311e-11\n",
            "  6.1688875e-16 6.9847313e-13 4.1973736e-09 1.4559242e-15 2.6403652e-14]]\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n",
            "iteration: 2\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "[[8.6538157e-06 2.2171840e-14 9.9998999e-01 3.9152133e-07 4.3316595e-09\n",
            "  2.9215705e-09 8.2117857e-13 8.3156004e-07 4.4565374e-09 8.3445919e-08]]\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "[[5.3238342e-10 8.7553836e-13 9.9999571e-01 4.2412980e-06 1.8193659e-10\n",
            "  7.7782634e-09 8.1627000e-14 7.3430200e-13 1.4539387e-12 6.8959294e-10]]\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[[1.9041973e-07 4.7554041e-11 9.9953771e-01 3.8308958e-06 1.8479712e-09\n",
            "  7.5686107e-10 2.6791144e-11 4.4055175e-04 8.0166146e-06 9.7360362e-06]]\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "[[4.8813609e-12 1.7528368e-26 1.0000000e+00 2.1308771e-13 6.1783076e-16\n",
            "  5.0412312e-20 5.6484233e-23 1.5453764e-13 2.1679843e-19 2.1327868e-18]]\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[2.0233417e-09 1.9711999e-13 9.9999726e-01 2.7611491e-06 4.5126275e-10\n",
            "  8.1884249e-11 1.9323408e-12 1.2843387e-10 2.7132957e-08 2.8803939e-08]]\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "iteration: 3\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[1.28565162e-07 1.50011212e-14 1.84913806e-05 9.97086823e-01\n",
            "  5.62138638e-08 1.06337744e-07 1.20594437e-10 9.94594739e-05\n",
            "  1.34537659e-05 2.78148171e-03]]\n",
            "tf.Tensor([3], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "[[6.4283512e-08 1.9787223e-12 2.1648564e-05 9.9568778e-01 4.1297838e-07\n",
            "  2.0661410e-06 1.2302201e-09 2.6500819e-08 7.9867692e-05 4.2082826e-03]]\n",
            "tf.Tensor([3], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "[[1.1494590e-09 1.4350912e-13 1.6198038e-09 9.9997556e-01 5.5980320e-10\n",
            "  3.6648160e-09 5.4464006e-10 4.3320742e-06 2.0897352e-07 1.9963189e-05]]\n",
            "tf.Tensor([3], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[[6.2303793e-09 6.1067806e-07 3.8968222e-03 9.9610019e-01 3.1974164e-07\n",
            "  1.5442296e-06 8.7276057e-08 5.9392553e-09 3.9906784e-08 4.7358873e-07]]\n",
            "tf.Tensor([3], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "[[2.1881444e-12 9.1892528e-19 1.4531867e-14 1.0000000e+00 1.1809841e-10\n",
            "  4.5679391e-11 1.5358498e-13 1.3951930e-11 7.2750765e-09 1.7336413e-08]]\n",
            "tf.Tensor([3], shape=(1,), dtype=int64)\n",
            "iteration: 4\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "[[4.8315640e-09 2.8595810e-11 2.2369568e-09 1.2430673e-10 9.9999475e-01\n",
            "  4.0780192e-06 1.1454950e-06 4.1278577e-13 2.9140976e-10 6.1940728e-09]]\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "[[3.1018744e-17 1.7332103e-13 1.8600519e-17 2.2561046e-13 1.0000000e+00\n",
            "  6.3351061e-13 2.1006509e-10 1.0823668e-17 1.0169202e-12 8.3246532e-10]]\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[1.63523319e-18 4.46395915e-12 3.84468767e-20 1.50105104e-16\n",
            "  1.00000000e+00 1.07417134e-13 3.89045393e-12 8.28146429e-18\n",
            "  2.65293366e-15 9.14055887e-10]]\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "[[3.5543552e-14 1.3019788e-08 2.3906888e-16 2.8501429e-11 1.0000000e+00\n",
            "  5.5396762e-13 9.2069667e-09 1.0176710e-12 2.7170537e-11 8.2636836e-10]]\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "[[1.8794834e-22 1.4597373e-25 1.6996070e-27 2.2319474e-17 1.0000000e+00\n",
            "  4.9536506e-14 7.9275336e-17 6.6268568e-26 1.1665708e-14 1.1456741e-09]]\n",
            "tf.Tensor([4], shape=(1,), dtype=int64)\n",
            "iteration: 5\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "[[1.43972360e-11 2.49618983e-14 4.48349362e-16 6.15019480e-10\n",
            "  5.26218969e-07 9.99998689e-01 7.13603640e-07 1.04605835e-19\n",
            "  3.72744786e-08 3.32342154e-08]]\n",
            "tf.Tensor([5], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "[[2.1349807e-11 2.5825370e-12 5.4138437e-15 5.1218046e-19 1.3338821e-08\n",
            "  9.9999070e-01 9.3247290e-06 4.2281397e-17 1.6337851e-09 4.8382925e-10]]\n",
            "tf.Tensor([5], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[[4.3287852e-07 8.0529236e-11 7.5181067e-13 6.6120398e-10 1.2184373e-04\n",
            "  8.8218081e-01 1.1761625e-01 1.1443241e-14 1.6752554e-06 7.8942387e-05]]\n",
            "tf.Tensor([5], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "[[4.0229209e-18 6.2128722e-20 1.4791526e-20 3.2356675e-17 1.4609629e-10\n",
            "  1.0000000e+00 3.6508834e-12 2.9118915e-28 3.2871004e-12 8.0521033e-12]]\n",
            "tf.Tensor([5], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "[[1.8897563e-15 1.0502321e-15 7.0191709e-14 2.7673175e-17 2.2082371e-11\n",
            "  1.0000000e+00 1.4913115e-12 3.2606048e-20 3.2886402e-10 1.9926295e-11]]\n",
            "tf.Tensor([5], shape=(1,), dtype=int64)\n",
            "iteration: 6\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[2.2757556e-10 1.8877432e-07 3.2570894e-11 3.9074195e-11 1.4104829e-06\n",
            "  1.8821769e-08 9.9992192e-01 1.0504020e-16 7.6383862e-05 1.4745216e-09]]\n",
            "tf.Tensor([6], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[2.4918482e-08 1.2796914e-10 4.6406767e-12 9.3793466e-15 2.4017702e-10\n",
            "  1.3789893e-10 1.0000000e+00 2.1664394e-18 3.9975468e-08 2.5326375e-13]]\n",
            "tf.Tensor([6], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[3.6855895e-06 2.8806630e-09 4.8505969e-14 1.4358639e-11 3.6962604e-07\n",
            "  2.4725288e-10 9.9999595e-01 9.1037993e-12 1.2538594e-08 5.7846945e-09]]\n",
            "tf.Tensor([6], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "[[3.2441470e-09 4.8204819e-19 3.6518398e-22 2.3295382e-20 1.4795415e-13\n",
            "  6.3140319e-13 1.0000000e+00 3.4751699e-23 2.8665227e-13 2.6743196e-17]]\n",
            "tf.Tensor([6], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[1.3657268e-09 4.7387741e-15 1.6746839e-16 8.2237593e-18 5.7702298e-12\n",
            "  1.4020901e-13 1.0000000e+00 2.5361910e-24 2.0284526e-08 5.1736151e-19]]\n",
            "tf.Tensor([6], shape=(1,), dtype=int64)\n",
            "iteration: 7\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[5.0466787e-07 3.8135240e-06 1.0748868e-08 3.7711082e-08 1.6407268e-08\n",
            "  2.8551774e-09 5.0330018e-10 9.9999571e-01 4.7241910e-10 9.0539398e-09]]\n",
            "tf.Tensor([7], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[2.5075403e-10 4.1517561e-07 2.5537249e-15 2.7615078e-12 1.1555435e-19\n",
            "  3.7535602e-21 5.0547747e-17 9.9999964e-01 4.5458151e-12 5.9234232e-16]]\n",
            "tf.Tensor([7], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "[[1.4420140e-06 1.2546400e-07 4.8759166e-08 2.8098529e-04 1.4538534e-06\n",
            "  1.5093251e-08 8.3814538e-09 9.9958402e-01 1.2956217e-08 1.3189299e-04]]\n",
            "tf.Tensor([7], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[5.8877819e-10 2.7567160e-11 2.6537716e-09 1.3004444e-09 7.9890090e-17\n",
            "  1.2108934e-19 1.1416296e-17 1.0000000e+00 3.1351078e-12 9.6395140e-12]]\n",
            "tf.Tensor([7], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "[[1.2965974e-10 3.5169607e-11 4.1844341e-08 9.6604648e-11 8.2904409e-18\n",
            "  1.8392866e-17 1.2230249e-17 1.0000000e+00 6.7117176e-14 3.5952827e-12]]\n",
            "tf.Tensor([7], shape=(1,), dtype=int64)\n",
            "iteration: 8\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[5.1139639e-12 6.8495922e-14 2.6935450e-11 6.4520667e-12 3.1577360e-10\n",
            "  3.0697028e-10 2.4368745e-08 5.2761037e-17 1.0000000e+00 5.0152784e-09]]\n",
            "tf.Tensor([8], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[1.65235658e-09 7.08813637e-14 9.52847935e-13 6.31154577e-08\n",
            "  1.05411395e-07 1.73538909e-04 2.45346251e-04 2.06731940e-17\n",
            "  9.99580801e-01 8.32260056e-08]]\n",
            "tf.Tensor([8], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[1.3009249e-04 1.8201057e-08 4.5124762e-06 3.6352247e-08 1.8333089e-06\n",
            "  4.6086853e-07 4.9037828e-07 2.5456977e-08 9.9273163e-01 7.1308194e-03]]\n",
            "tf.Tensor([8], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[6.10153393e-06 2.11828507e-07 3.13216681e-03 1.18113094e-04\n",
            "  3.07164925e-07 4.45797923e-06 1.01487085e-05 2.39670157e-07\n",
            "  9.96334195e-01 3.94056668e-04]]\n",
            "tf.Tensor([8], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[2.65940952e-14 6.69073504e-20 1.12771023e-12 2.45314533e-12\n",
            "  1.05668088e-17 1.09903054e-16 1.35009276e-14 2.67435888e-18\n",
            "  1.00000000e+00 3.51489129e-13]]\n",
            "tf.Tensor([8], shape=(1,), dtype=int64)\n",
            "iteration: 9\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1.4820624e-07 5.0752074e-06 3.2098002e-10 1.3492993e-07 1.7851703e-01\n",
            "  9.4572520e-08 1.1062587e-05 1.7132199e-06 4.4861409e-07 8.2146424e-01]]\n",
            "tf.Tensor([9], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[2.0963253e-02 9.5876806e-10 3.0937976e-08 3.6678955e-13 2.2439010e-01\n",
            "  2.6415514e-11 2.6182281e-06 1.8895495e-06 2.9034271e-07 7.5464189e-01]]\n",
            "tf.Tensor([9], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[3.9441361e-13 1.0071810e-14 1.3892843e-12 3.2350706e-13 5.5653295e-09\n",
            "  1.3803372e-06 8.7796138e-11 7.7156067e-16 6.6607790e-08 9.9999845e-01]]\n",
            "tf.Tensor([9], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[1.9122874e-15 3.4793207e-16 2.7814994e-17 2.1956747e-19 2.4877878e-08\n",
            "  1.1473446e-13 1.7878704e-13 3.0374972e-16 9.5833878e-18 1.0000000e+00]]\n",
            "tf.Tensor([9], shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[6.0161213e-14 1.3093933e-13 6.8953688e-19 6.8650585e-18 2.8110310e-04\n",
            "  2.4919162e-09 1.3963640e-10 6.8233734e-15 1.6116039e-10 9.9971884e-01]]\n",
            "tf.Tensor([9], shape=(1,), dtype=int64)\n",
            "[[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3], [4, 4, 4, 4, 4], [5, 5, 5, 5, 5], [6, 6, 6, 6, 6], [7, 7, 7, 7, 7], [8, 8, 8, 8, 8], [9, 9, 9, 9, 9]]\n",
            "Accuracy: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def most_frequent_element(lst):\n",
        "    return max(lst, key=lst.count)\n",
        "\n",
        "for res in pred_res:\n",
        "  result = most_frequent_element(res)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "hcivUg_WgdCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942efd2c-231e-44a4-d006-70f9a659a998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict the handwriting of the input images"
      ],
      "metadata": {
        "id": "LFN3Qc3X-fCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "bJnRIbmm4YJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import shap\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "Hf2mA2QL4avd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((28, 28))  # Resize image\n",
        "\n",
        "    img_rgb = img.convert('RGB')  # Convert to RGB for model\n",
        "    img_rgb = np.array(img_rgb)  # Convert image to array\n",
        "    img_rgb = img_rgb / 255.0  # Normalize\n",
        "    img_rgb = np.expand_dims(img_rgb, 0)  # Add batch dimension\n",
        "\n",
        "    img_bin = img.convert('1')  # Convert to binary for visualization\n",
        "    img_bin = np.array(img_bin, dtype=np.int32)  # Convert image to integer array\n",
        "\n",
        "    return img_rgb, img_bin\n",
        "\n",
        "\n",
        "samples_per_class = 1  # We only need one representative sample per class\n",
        "representative_samples = []\n",
        "representative_images = []\n",
        "\n",
        "# Load one image per class from each class folder\n",
        "for i in range(10):\n",
        "    image_paths = glob.glob(f'{testing_dir}/{i}/*_resized.png')[:samples_per_class]\n",
        "    for path in image_paths:\n",
        "        img_rgb, img_bin = load_and_preprocess_image(path)\n",
        "        representative_samples.append(img_rgb)\n",
        "        representative_images.append(np.expand_dims(img_bin, -1))  # Add an extra dimension for grayscale\n",
        "\n",
        "# Convert to Tensor for compatibility with SHAP\n",
        "to_explain = tf.convert_to_tensor(np.concatenate(representative_samples))\n",
        "\n",
        "# Convert representative_images to a numpy array and invert the colors\n",
        "representative_images = 1 - np.array(representative_images)\n",
        "\n",
        "# Convert representative_images to a numpy array\n",
        "representative_images = np.array(representative_images)\n",
        "\n",
        "# Create an explainer object\n",
        "explainer = shap.DeepExplainer(new_model, to_explain)\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_values = explainer.shap_values(to_explain)\n",
        "\n",
        "shap.image_plot(shap_values, -representative_images)"
      ],
      "metadata": {
        "id": "-8H3xohe4dh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = 0\n",
        "member_error_list = []\n",
        "for i in range(len(pred_res)):\n",
        "  for j in range(len(pred_res[i])):\n",
        "    curr_res = pred_res[i][j] # this will take the predicted result from digit recognition model\n",
        "    # load the current image into the corresponding model based on the previous predicted result\n",
        "    # for example, if the digit detected from previous model is 4\n",
        "    # then the current image will be fitted into the \"handwriting_4_recognition_model\"\n",
        "    y_pred = handwriting_model_list[curr_res].predict(np.expand_dims(loaded_images[i][j]/255, 0))\n",
        "    # take the result with the highest probability\n",
        "    y_pred_classes = int(tf.argmax(y_pred, axis=1))\n",
        "    # print the filename, the predicted digit and the predicted memeber who wrote that image\n",
        "    print(y_pred)\n",
        "    print(f'member {y_pred_classes}')\n",
        "    print(\"-------------------------------------------------------------------------------------\")\n",
        "    print(f'filename: {filename_list[i][j]} --- predicted digit: {curr_res} --- predicted written by: {member_list[y_pred_classes]}')\n",
        "    print(\"-------------------------------------------------------------------------------------\")\n",
        "    parts = filename_list[i][j].split('_')\n",
        "    member = parts[0]\n",
        "    digit = int(parts[1])\n",
        "    # compare the predicted digit and member with the filename (actual digit and member name)\n",
        "    # count the correct predictions\n",
        "    if member == member_list[y_pred_classes] and digit == curr_res:\n",
        "      print('---> right prediction\\n')\n",
        "      score+=1\n",
        "    else:\n",
        "      print('---> wrong prediction\\n')\n",
        "      member_error_list.append(member)\n",
        "\n",
        "# calculate the accuracy of the testing set in prercentage\n",
        "print(f'Accuracy: {score/50*100}%')\n",
        "\n",
        "print(member_error_list)"
      ],
      "metadata": {
        "id": "9YG-qi9ug8eS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4deef623-c453-416e-fbf4-61b435ed3992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "[[0.0041054  0.14009868 0.8421198  0.01238233 0.00129377]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_0_resized.png --- predicted digit: 0 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[2.0729951e-04 9.9757845e-03 6.5185567e-03 3.9160859e-02 9.4413751e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_0_resized.png --- predicted digit: 0 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[9.9999630e-01 2.0733594e-07 3.6404387e-07 2.7896178e-06 3.9186077e-07]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_0_resized.png --- predicted digit: 0 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1.6724000e-07 1.0083234e-02 4.1359946e-02 5.6218600e-04 9.4799447e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_0_resized.png --- predicted digit: 0 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[2.1494755e-07 9.9840397e-01 5.0291092e-06 3.8312677e-08 1.5908132e-03]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_0_resized.png --- predicted digit: 0 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "[[0.00097113 0.00637858 0.3051662  0.66583186 0.0216522 ]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_1_resized.png --- predicted digit: 1 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[0.00468297 0.12992053 0.45317253 0.4077657  0.00445825]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_1_resized.png --- predicted digit: 1 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[9.8317206e-01 7.4278717e-03 4.0221172e-03 3.0261828e-04 5.0753392e-03]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_1_resized.png --- predicted digit: 1 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[1.6339184e-03 5.7728767e-01 3.1415033e-01 1.0656824e-01 3.5968274e-04]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_1_resized.png --- predicted digit: 1 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[3.6957526e-06 4.6111492e-09 7.0052681e-07 9.0088456e-08 9.9999547e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_1_resized.png --- predicted digit: 1 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "[[2.2620759e-06 2.7277335e-04 7.7374214e-01 2.2597151e-01 1.1307823e-05]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_2_resized.png --- predicted digit: 2 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[9.9400228e-01 5.9977314e-03 6.8542455e-10 1.8278222e-10 5.3320311e-16]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_2_resized.png --- predicted digit: 2 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[1.6132655e-07 9.4888252e-05 9.9226534e-01 7.3282020e-03 3.1139021e-04]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_2_resized.png --- predicted digit: 2 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[2.3892538e-19 5.7671984e-10 5.2283506e-09 3.2568814e-09 1.0000000e+00]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_2_resized.png --- predicted digit: 2 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1.0000000e+00 8.1342016e-10 1.4715312e-14 1.2232258e-13 8.5700274e-20]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_2_resized.png --- predicted digit: 2 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "[[1.0475597e-03 3.7868958e-04 9.8754591e-01 9.8984931e-03 1.1292824e-03]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_3_resized.png --- predicted digit: 3 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[0.79037553 0.16916087 0.01618333 0.02226873 0.00201155]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_3_resized.png --- predicted digit: 3 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[4.8952857e-06 1.0605246e-05 1.2811903e-03 9.9759561e-01 1.1076737e-03]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_3_resized.png --- predicted digit: 3 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[9.9997997e-01 1.5954909e-05 7.9473085e-07 3.1400275e-06 1.3654574e-07]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_3_resized.png --- predicted digit: 3 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "[[8.6097387e-09 1.3775354e-04 2.3614908e-02 5.0338019e-02 9.2590934e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_3_resized.png --- predicted digit: 3 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "[[1.6689088e-09 4.7587584e-10 1.9177148e-06 9.9999809e-01 5.2535709e-09]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_4_resized.png --- predicted digit: 4 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[1.8729010e-04 2.5846325e-02 8.7492776e-01 9.0350769e-02 8.6877942e-03]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_4_resized.png --- predicted digit: 4 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[6.9090700e-01 3.0773818e-01 1.3527636e-03 9.4754625e-08 1.8685414e-06]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_4_resized.png --- predicted digit: 4 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[9.9989927e-01 7.6964396e-05 2.3605351e-05 1.6713304e-09 8.6109637e-08]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_4_resized.png --- predicted digit: 4 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[1.1601429e-07 3.5573664e-04 4.8220933e-08 1.5106777e-07 9.9964392e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_4_resized.png --- predicted digit: 4 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "[[8.4187076e-07 1.3199011e-07 3.6553103e-01 6.1178470e-01 2.2683263e-02]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_5_resized.png --- predicted digit: 5 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[1.5186459e-04 9.9957687e-01 2.7132084e-04 1.8608387e-11 2.7389119e-08]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_5_resized.png --- predicted digit: 5 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[6.7824709e-07 1.5064718e-09 9.9325198e-01 2.3133582e-06 6.7449529e-03]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_5_resized.png --- predicted digit: 5 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[1.0496461e-17 1.0429743e-14 6.9812856e-08 6.4664468e-11 9.9999988e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_5_resized.png --- predicted digit: 5 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[9.9999809e-01 5.8889751e-09 1.9380273e-06 5.6592491e-12 1.7077111e-12]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_5_resized.png --- predicted digit: 5 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "[[0.00095293 0.00322279 0.47336742 0.52183735 0.00061952]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_6_resized.png --- predicted digit: 6 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[2.2180150e-03 7.2669233e-03 9.7913641e-01 1.1301955e-02 7.6666911e-05]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_6_resized.png --- predicted digit: 6 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[9.9950886e-01 2.6094055e-04 1.1070930e-06 2.2832229e-04 8.5111708e-07]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_6_resized.png --- predicted digit: 6 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[3.0080759e-05 9.9969685e-01 3.2769804e-05 1.9797639e-04 4.2395674e-05]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_6_resized.png --- predicted digit: 6 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[5.5377586e-10 1.2897171e-05 7.2770366e-05 4.5072529e-06 9.9990976e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_6_resized.png --- predicted digit: 6 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "[[5.5564311e-07 5.5958895e-05 9.9886715e-01 1.0009989e-03 7.5256627e-05]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_7_resized.png --- predicted digit: 7 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[9.6479481e-01 2.1209378e-02 4.6940249e-06 1.9132353e-03 1.2077918e-02]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_7_resized.png --- predicted digit: 7 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[6.3744051e-07 7.0078287e-04 3.8221568e-01 5.6542820e-01 5.1654730e-02]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_7_resized.png --- predicted digit: 7 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[2.7377000e-06 7.0809794e-05 1.7126364e-05 4.5133470e-06 9.9990475e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_7_resized.png --- predicted digit: 7 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[3.0561134e-01 6.7469376e-01 7.0466565e-05 2.4120729e-04 1.9383192e-02]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_7_resized.png --- predicted digit: 7 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "[[4.0257479e-08 5.2523433e-06 2.0490059e-01 7.9421520e-01 8.7886036e-04]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_8_resized.png --- predicted digit: 8 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[4.37466241e-07 2.54106181e-09 9.98799086e-01 1.08456402e-03\n",
            "  1.15833536e-04]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_8_resized.png --- predicted digit: 8 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[9.9979848e-01 1.3062767e-06 7.5184187e-07 1.8708786e-04 1.2340829e-05]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_8_resized.png --- predicted digit: 8 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> wrong prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[9.99995232e-01 1.75128582e-06 5.74594537e-07 2.23094912e-06\n",
            "  1.13765644e-07]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_8_resized.png --- predicted digit: 8 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[3.9021986e-09 8.9304103e-10 1.6909413e-10 8.5885713e-06 9.9999142e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_8_resized.png --- predicted digit: 8 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "[[3.2324539e-09 7.8298791e-11 3.2300599e-05 9.9986815e-01 9.9518940e-05]]\n",
            "member 3\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: HT_9_resized.png --- predicted digit: 9 --- predicted written by: HT\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[9.1821406e-08 3.3832682e-04 8.4532243e-01 1.5133424e-01 3.0049197e-03]]\n",
            "member 2\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YO_9_resized.png --- predicted digit: 9 --- predicted written by: YO\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[5.0366926e-01 4.9617755e-01 6.6882109e-07 9.0900699e-05 6.1548628e-05]]\n",
            "member 0\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: CY_9_resized.png --- predicted digit: 9 --- predicted written by: CY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[3.3491437e-12 1.2176909e-10 8.7592149e-11 5.3276221e-04 9.9946719e-01]]\n",
            "member 4\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: ZY_9_resized.png --- predicted digit: 9 --- predicted written by: ZY\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[3.5522231e-07 9.9998760e-01 4.8962949e-08 1.0137391e-05 1.8588743e-06]]\n",
            "member 1\n",
            "-------------------------------------------------------------------------------------\n",
            "filename: YJ_9_resized.png --- predicted digit: 9 --- predicted written by: YJ\n",
            "-------------------------------------------------------------------------------------\n",
            "---> right prediction\n",
            "\n",
            "Accuracy: 84.0%\n",
            "['HT', 'HT', 'YJ', 'YJ', 'YJ', 'YJ', 'CY', 'YJ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the total number of wrong prediction by each member\n",
        "from collections import Counter\n",
        "\n",
        "counts = Counter(member_error_list)\n",
        "\n",
        "for member, count in counts.items():\n",
        "    print(f'{member} error(s): {count}')"
      ],
      "metadata": {
        "id": "C3N7s_k8pSWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11722fe7-8692-40e4-fff9-eab5f703716a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HT error(s): 2\n",
            "YJ error(s): 5\n",
            "CY error(s): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result above shows Hon Ting(HT), Yan Jian(YJ) and Ching Yen(CY) have at least one wrongly predicted handwriting out of 10 test images provided.\n",
        "The other two members who are Yun Onn(YO) and Zheng Yu(ZY) have all the handwritting images predicted correctly.\n",
        "It means that except for YJ, the other 4 members have a relatively consistent handwriting pattern."
      ],
      "metadata": {
        "id": "_gzoNcddAhj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, YJ has more 5 wrong predictions out of 10 test images provided which are digit 2, 3, 4, 7 and 8.\n",
        "It means that YJ has a relatively inconsistent handwriting pattern."
      ],
      "metadata": {
        "id": "ew4Et93fBFTs"
      }
    }
  ]
}